\input{coverpage}
\documentclass[11.5pt]{article}
\usepackage{titling}
\usepackage{sbc-template}
\usepackage{graphicx,url}
\usepackage[brazil]{babel}
\usepackage[utf8]{inputenc}

\usepackage{multicol}
\usepackage{multirow}
\usepackage{setspace,lipsum}
\usepackage[toc,page]{appendix}

\sloppy

\date{\today}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{
    Estudo de Caso da Correlação Entre Cobertura de Código e Falhas Reportadas em um Sistema
    Operacional
}

\local{Porto Alegre}

\author{George Redivo Pinto}

\preambulo{Trabalho apresentado à disciplina Engenharia de Software Aplicada, pelo Curso de
Especialização em Engenharia de Software da Universidade do Vale do Rio dos Sinos - UNISINOS,
ministrada pela professora Josiane Brietzke Porto.}

\address{
  Universidade do Vale do Rio dos Sinos (UNISINOS)\\
  Porto Alegre -- RS -- Brasil
}

\instituicao{
    UNIVERSIDADE DO VALE DO RIO DOS SINOS – UNISINOS

    UNIDADE ACADÊMICA DE PESQUISA E PÓS-GRADUAÇÃO

    ESPECIALIZAÇÃO EM ENGENHARIA DE SOFTWARE
}

\begin{document}

\imprimircapa
\imprimirfolhaderosto

\maketitle

\begin{abstract}

Software testing is an important step in software development cycle. This step aims to ensure that
the code works according to the specification.
Code coverage is a metric that tries to measure the test quality by indicating the percentage of
code that were used during test execution.
This article aims to research the correlation between code coverage rate and software quality,
measured by reported faults.
To do that it was done a case study using the features of an operational system and the results
indicate that there is a correlation between code coverage rate and software quality.

\end{abstract}

\begin{resumo}

O teste de \textit{software} é uma importante etapa no processo de desenvolvimento de \textit{software}. Essa etapa
visa garantir que o \textit{software} funciona de acordo com as especificações.
A cobertura de código é uma métricas que se propõe a medir a qualidade de um teste. Ela consiste em
prover uma taxa percentual que indica a porcentagem de código executadas nos testes.
O presente artigo visa estudar se existe ou não correlação entre a cobertura de código e a
qualidade do \textit{software}, medida em quantidade de falhas reportadas.
Para tal, foi feito um estudo de caso utilizando as funcionalidades de um sistema operacional,
chegando em um resultado que indica a existência de correlação entre cobertura de ódigo e
qualidade de \textit{software}.


\end{resumo}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Introdução}

A etapa de teste de \textit{software} é uma etapa importante no processo de desenvolvimento de
\textit{software} e está cada vez mais presente no cotidiano das equipes de desenvolvimento de
\textit{software}.
Essa etapa visa garantir a funcionalidade de um dado \textit{software}, podendo ser feita utilizando
diversos métodos e em diversos níveis, de acordo com a finalidade do teste.
Contudo, o desenvolvimento de testes implica em um impacto financeiro no projeto, uma vez que muitas
horas e profissionais são demandados para a escrita de testes.

A cobertura de código é uma métrica que indica a porcentagem de código que está sendo coberta pelos
testes executados.
Essa métrica ajuda a medir a qualidade dos casos de teste em questão e também pode servir como uma
métrica que indica quando podemos parar de escrever testes, ou seja, quando já temos uma quantidade
suficiente de testes para cobrir um determinado código, com a finalidade de redução de custos.
Contudo, a decisão pela parada da escrita de testes pode impactar na qualidade do \textit{software}
final, uma vez que alguns casos de uso podem ficar descoberto pelos testes.
Por esse motivo é imprescindível que tal decisão seja tomada baseada em dados sólidos, a fim de
evitar esforços excessivos no desenvolvimento de teste, porém garantindo a qualidade do
\textit{software}.
Segundo \cite{coverageAtGoogle}, a adoção da análise de cobertura de código vem crescendo ao longo
dos anos e tem uma boa avaliação de seus usuários quanto à sua efetividade, o que reafirma a
necessidade de que se tenha um bom conhecimento sobre a efetividade de tal métrica para medir
qualidade de teste e de \textit{software}.

Diversos estudos tentam verificar se existe, de fato, uma correlação entre cobertura de testes e
qualidade de \textit{software}, tais como \cite{coverageMetaAnalysis}, \cite{unitTestedCrash} e
\cite{coverageLargeScaleStudy}.
Os resultados obtidos por esses estudos são controversos entre si.
\cite{coverageMetaAnalysis} traz uma revisão sistemática de diversos artigos publicados sobre o
assunto e aponta algumas possíveis vulnerabilidades metodológicas nos artigos estudados, o que
sugere que mais estudos podem ser feitos para tentar delinear melhor a relação entre cobertura de
código e qualidade de \textit{software}.

Nesse sentido, o presente artigo tem por objetivo responder a seguinte questão de pesquisa:
existe correlação entre cobertura de código e qualidade de \textit{software} de um sistema
operacional embarcado, sendo cobertura de linhas a métrica de cobertura de código e número de falhar
reportadas a métrica de qualidade de \textit{software}?
Para tal, o estudo tem o objetivo de fazer um estudo de caso, conforme descrito em
\cite{metodosPesquisa}, em um projeto de sistema operacional embarcado desenvolvido por uma empresa
brasileira, observando as métricas supracitadas e usando métodos estatísticos para identificar a
correlação entre cobertura de código e qualidade de \textit{software}.
Nesse contexto, as seguintes etapas serão desenvolvidas:

\begin{itemize}
    \item Coletar dados de cobertura de código (por repositório) e falhas reportadas do projeto (por
          funcionalidade);

    \item Sanitizar dados, excluindo dados inválidos para a pesquisa;

    \item Relacionar os repositórios com as funcionalidades;

    \item Fazer análise estatística dos dados coletados.
\end{itemize}

Os resultados da presente pesquisa contribuem para uma maior clareza sobre a correlação entre
cobertura de código e qualidade de \textit{software}, o que pode ajudar a balizar decisões de
alocação de recursos humanos na atividade de escrita de testes de \textit{software}.
Além disso, os resultados obtidos podem ser usados como base acadêmica na área de Engenharia de
Software para um melhor entendimento dessa correlação, além de produzir insumos para estudos futuros
nesse mesmo contexto.

O artigo está dividido seis sessões, são elas:
\begin{enumerate}
    \item Introdução: tem por objetivo fornecer uma visão geral da presente pesquisa, além da
          motivação e etapas desenvolvidas;

    \item Fundamentação Teórica e Ferramentas: apresenta um embasamento teórico dos assuntos
          abortados no artigo, além de listar as principais ferramentas utilizadas na coleta,
          triagem e análise dos dados;

    \item Trabalhos Relacionados: revisita alguns trabalhos recentes relacionados ao tema da
          presente pesquisa;

    \item Metodologia de Pesquisa: apresenta a metodologia utilizada no desenvolvimento do estudo
          proposto;

    \item Resultados: detalha os resultados obtidos da análise dos dados;

    \item Considerações Finais: faz um resumo dos resultados, vulnerabilidades da pesquisa, além de
          indicar possíveis estudos complementares.
\end{enumerate}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Fundamentação Teórica e Ferramentas}

Esta sessão contém o referencial teórico relativo aos principais conceitos envolvidos no presente
estudo.
Além disso, serão descritas as principais ferramentas utilizadas durante as fases coleta,
sanitização, triagem e análise dos dados utilizados no estudo.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Testes de Software}

A etapa de teste de \textit{software} consiste em verificar que um \textit{software} funciona de
acordo com os requisitos, buscando por defeitos no \textit{software} em teste
\cite{engSwSommerville}.
Podemos utilizar a definição de defeito descrita em \cite{introTeste}, que descreve como ``um passo,
processo ou definição de dados incorretos''.

Tais testes podem ser manuais ou automáticos.
Segundo \cite{engSwSommerville}, nos testes manuais o testador executa o programa manualmente,
injetando alguns dados, e compara o resultado com o que ele espera que seja o resultado correto.
Já nos testes automáticos, ou automatizados, os casos de teste são codificados em um programa
responsável pela execução dos testes.
Esse programa é injeta os dados de entrada no \textit{software} testado e verifica se os resultados
estão de acordo com o esperado.

Dentro do contexto de teste de \textit{software} podemos subdividir os testes em diversas
categorias. Ao decorrer do presente trabalho, veremos duas categorias principais: testes funcionais
e testes estruturais.
Testes funcionais (ou de caixa-preta) caracterizam-se por testes onde não consideramos aspectos
internos do programa a ser testado e é avaliado mais do ponto de vista do usuário \cite{introTeste}.
Já testes estruturais (ou de caixa-branca) são testes baseados na implementação do programa, levando
em conta laços de execução, condicionais, definições e usos de variáveis, entre outros
\cite{introTeste}.

Uma outra categorização de testes importante de ser mencionada é a categorização por granularidade.
Em \cite{engSwSommerville} o autor divide os testes em 3 níveis de granularidade:
(1) teste unitário, onde é testada a menor parte viável de um programa,
(2) teste de componente, onde o teste integra diversas unidades de um programa e, por fim,
(3) teste de sistema, onde o sistema é testado como um todo, englobando alguns ou todos os
componente.

Neste estudo nos debruçaremos sobre uma parcela dos testes automáticos do caso em questão, pois são
esses testes que são capazes de fornecer os dados que iremos utilizar. A sessão
\ref{Unidade de Análise} trará mais detalhes sobre os testes utilizados neste estudo.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Cobertura de Código}

O fato de um teste automático de \textit{software} não encontrar defeitos não implica em o
\textit{software} não ter defeitos.
O desenvolvedor do teste pode não ter implementado testes suficientes para todos os casos possíveis,
o que pode fazer com que existam defeitos não encontrados pelos testes \cite{engSwSommerville}.

Existem diversas formas de tentar medir a qualidade de um teste, isto é, o quão bem este teste
consegue cobrir o \textit{software} que está sendo testado.
Uma dessas formas é a cobertura de código.

Segundo a definição de \cite{tddBook}, ``cobertura de código é a métrica que nos diz a quantidade de
código que está testada e a quantidade de código onde nenhum teste o exercita".
Essa ``quantidade de código'' pode ser visualizada de diversas formas, como cobertura de linhas,
cobertura de decisão, ou \textit{decision coverage}, em inglês, cobertura de métodos, entre outras.
Neste estudo iremos utilizar como métrica a cobertura de linhas de código, visto que no projeto em
estudo os dados de cobertura são reportados neste formato.

As métricas de cobertura de código podem ser extraídas utilizando diversas ferramentas, de acordo
com a tecnologia adotada no projeto.
O projeto do caso de estudo é implementado em sua maioria utilizando a linguagem C++, o
Google Test \cite{googleTest} como \textit{framework} de testes Google Test \cite{googleTest} e
a cobertura de código é calculada utilizando gcov \cite{gcov}.

Uma vez que uma alta taxa de cobertura de linhas código indica que o programa testado está, em
grande parte, coberto por testes automáticos, então pode-se pensar que o critério de cobertura de
código pode ser uma métrica de qualidade do \textit{software} testado, e não apenas qualidade do
código.
É nesse contexto que o presente estudo utilizará as métricas de cobertura de código para verificar
se, de fato, existe uma correlação que confirme tal suposição.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Regressão Linear e Correlação}

Ao decorrer da análise dos dados deste estudo será necessária uma análise estatística para respoder
a questão de pesquisa proposta.
Para tal, faremos o uso de algumas ferramentas estatísticas, tais como regressão linear e índice de
correlação.

No presente estudo teremos como principais os dados de (1) quantidade de falhas reportadas e (2)
taxa de cobertura de código.
Para verificarmos se existe alguma tendência entre os valores podemos utilizar a
\textbf{regressão linear}.

Segundo \cite{openIntroStat}, modelos de regressão linear podem ser usados para previsões com base
em dados de duas variáveis numéricas. A Figura~\ref{fig:lin_reg_example} mostra um exemplo de
regressão linear, onde a tendência é de que os valores do eixo \textbf{y} subam à medida que os
valores do eixo \textbf{x} sobem.

\begin{figure}[ht]
    \centering
    \includegraphics[width=.3\textwidth]{lin_reg_example.png}
    \caption{Exemplo de regressão linear. Fonte: \cite{openIntroStat}}
    \label{fig:lin_reg_example}
\end{figure}

Outra ferramenta que iremos utilizar neste artigo é o cálculo de correlação.
Segundo \cite{openIntroStat}, a correlação (\textit{R}) é uma medida com valor entre -1 e 1 que
indica o quão forte é a tendência linear entre as variáveis numéricas estudadas.
Quanto mais próximo de -1 for \textit{R}, maior é a força de correlação negativa.
Quanto mais próximo de 1 for \textit{R}, maior é a força de correlação positiva.
Por fim, quando mais próximo de 0 for \textit{R}, menor é a força de correlação entre os valores
estudados. A Figura~\ref{fig:correlation_example} mostra oito exemplos de correlação.

\begin{figure}[ht]
    \centering
    \includegraphics[width=.7\textwidth]{correlation_example.png}
    \caption{Exemplo correlação entre variáveis. Fonte: \cite{openIntroStat}}
    \label{fig:correlation_example}
\end{figure}

Com essas ferramentas estatísticas podemos verificar se existe alguma tendência entre os dados
estudados e, caso exista, qual a força da correlação entre elas.
É importante salientar que as tendencias e correlações calculadas não implicam em causalidade,
apenas nos dão insumos para uma análise mais criteriosa.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Ferramentas}

Diversas ferramentas foram utilizadas durante a obtenção, triagem e análise dos dados estudados
neste artigo.

O Bugzilla \cite{bugzilla} é um sistema de gerenciamento de defeitos que possibilita a organização,
categorização e discussão de defeitos reportados.
O projeto do qual os dados foram coletados utiliza o Bugzilla como sistema de gerenciamento de
defeitos. Nele existe um campo chamado ``\textit{Component}'' que é utilizado para indicar a qual
funcionalidade, do ponto de vista do usuário, aquele defeito é relativo, que será utilizado para
categorização dos defeitos neste presente estudo.

Os resultados de cobertura de código, no projeto estudado, são calculados pelo gcov \cite{gcov}, que
se trata de uma ferramente para geração de dados de cobertura de código para ser usada em conjunto
com o compilador \textbf{GCC} \cite{gcc}.

No projeto estudado, os testes, incluindo geração de dados de cobertura de código, são executados
automaticamente pelo Jenkins \cite{jenkins} (ferramenta para automatizações de integração contínua)
toda a vez que um novo \textit{commit} é submetido para revisão ou para o \textit{branch} principal.
Além dos resultados dos testes (sucesso ou falha) também são publicizados os dados de cobertura de
código calculados pelo gcov.

Na parte de triagem e análise dos dados, alguns \textit{scripts} em Python foram criados e estão
descritos em [REFERENCIAR APENDICES]. Nestes \textit{scripts} fora utilizadas as bibliotecas
(1) Plotly \cite{plotly}, uma biblioteca Python para geração de gráficos e (2) NumPy \cite{numpy},
uma biblioteca Python para auxílio em computação numérica.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Trabalhos Relacionados}

Em \cite{unitTestedCrash} os autores se propõe um estudo sobre a relação entre cobertura de código
a ocorrência de falhas, tentando traçar uma correlação entre os dois valores.
Como estudo de caso foram usados reportes de falhas em campo do projeto Eclipse.
O estudo coletou mais de 2 milhões de incidentes reportados e, após triagem de dados os autores
tinham em mãos mais de 126 mil reportes únicos do tipo \textit{stack trace}, que consiste em um tipo
de reporte de erro que contém informações como arquivo e linha de onde ocorreu a falha.

Em paralelo foram coletados dados da análise de cobertura de código do projeto em questão.
Como principal métrica de cobertura de código para a comparação foi utilizado a métrica de métodos
cobertos, que consiste em relacionar a quantidade de métodos existentes e quantos desses são
invocados nos testes.

Foi feita uma análise dos dados relacionando as falhas reportadas e a cobertura de código e a Tabela
\ref{tab:FalhasMetodosTeste} mostra os dados obtidos.
Do total de métodos analisados, 93,6\% não são testados 6,4\% dos testes são testados.
Analisando apenas os métodos que não possuem reportes de falhas relacionados essa proporção é de
93,5\% de métodos não testados, para 6,5\% de métodos testados.
Já quando analisamos métodos que possuem reportes de falhas relacionados essa proporção fica em
94,1\% de métodos não testados, para 5,9\% de métodos testados.

\begin{table}[ht]
\centering
\caption{Falhas de Métodos. Fonte: \cite{unitTestedCrash}}
\label{tab:FalhasMetodosTeste}
\begin{tabular}{|l|c|c|c|}
\hline
\multirow{2}{*}{Falha Reportada?} & \multicolumn{2}{c|}{Possui teste?} & \multirow{2}{*}{Total} \\ \cline{2-3}
                                  & Não   & Sim                        &       \\ \hline
Não                               & 7816  & 541                        & 8357  \\ \hline
Sim                               & 1097  &  69                        & 1166  \\ \hline
Total                             & 8913  & 619                        & 9523  \\ \hline
\end{tabular}
\end{table}

Com esse resultado o estudo conclui que não é possível afirmar que existe uma correlação entre
cobertura de código e uma menor quantidade de ocorrência de falhas. Os valores encontrados variam
marginalmente, apresentando um baixo valor de correlação.

Complementarmente, o artigo traz alguns itens a serem levados em conta.
Um deles é que o resultado foi utilizando apenas um projeto e tal projeto tem grandes proporções.
Os autores argumentam que o resultado não pode ser generalizado e pode vir a se diferente em outros
tamanhos de projeto.

O artigo \cite{coverageMetaAnalysis} traz uma revisão sistemática de outros trabalhos que analisam
uma possível correlação entre cobertura de código e efetividade de um conjunto de testes.
Para tal, os autores fizeram uma busca utilizando a ferramenta de busca Scopus para a seleção dos
trabalhos a serem estudados a fim de responder três questões de pesquisa:
\begin{enumerate}
    \item Quais evidências existem sobre a correlação entre cobertura de código e efetividade dos
          testes?

    \item Quais fatores impactam nessa relação?

    \item Qual métrica de cobertura de código é melhor para predizer a efetividade dos testes?
\end{enumerate}

O estudo descreve os termos de busca utilizados, além de duas etapas de filtragem de estudos que
foram necessárias para obter um material mais conciso para a revisão sistemática.
Após a primeira busca eles encontraram 427 resultados para a busca e, após os filtros retaram 33
estudos para serem analisados.

Segundo os autores, alguns estudos prévios apontavam que existe uma forte correlação entre cobertura
de código e efetividade dos testes.
Por outro lado alguns estudos indicavam que essa correlação era baixa ou até nula.

Como resultado desse artigo os autores argumentam que uma possível causa da não convergência dos
resultados dos estudos seja a falta de padronização entre os estudos, uma vez que os diversos
estudos revisados possuem abordagens diferentes de análise, além de casos de uso bem distintos entre
eles.
Para obter melhores resultados os autores recomendam atenção em alguns pontos que podem prejudicar
os resultados de estudos, tais como descartar projetos muito pequenos ou com uma cobertura
excessivamente baixa.
Outro ponto levantado pelos autores é uma lista de fatores que podem interferir na relação entre
cobertura de código e efetividade dos testes, como porcentagem de cobertura, testes que exercitem
tanto casos normais, quanto casos de exceção, tamanho do conjunto de testes, natureza das falhas,
complexidade do código, entre outros.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Metodologia de Pesquisa}

Essa pesquisa utilizou o método de estudo de caso e analisou os resultados por uma perspectiva
quantitativa.

Segundo \cite{estudoDeCasoYin}, ``você poderia utilizar o método de estudo de caso quando
deliberadamente quisesse lidar com condições contextuais - acreditando que elas poderiam ser
altamente pertinentes ao seu fenômeno de estudo''.
Nesse sentido o presente estudo utilizará como caso um sistema operacional embarcado em operação
desde 2015 em conjunto com suas métricas de cobertura de código e quantidade falhas encontradas.

Com base nos dados coletados, será feita uma análise quantitativa que, segundo
a definição de \cite{projetoDePesquisa}, utiliza raciocínio de causa e efeito, observação de dados,
teste de teorias, coleta de dados, entre outros instrumentos.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Delineamento de Pesquisa}

A presente pesquisa é de caráter quantitativo, visto que se pretende a traçar uma correlação entre
duas variáveis numéricas quantitativas -- percentual de cobertura de código e quantidade de falhas
reportadas.
Para descobrir de existe tal relação, os números encontrados serão submetidos a análises
estatísticas.

Para a coleta de dados, será feita uma pesquisa exploratória em um estudo de caso de um projeto
de sistema operacional.
Esse modelo de pesquisa é amplamente utilizado (\cite{coverageMetaAnalysis}, \cite{unitTestedCrash}
e \cite{coverageLargeScaleStudy}) em estudos do tipo, uma vez que a coleta de dados é precisa e de
fácil acesso, além de trazer uma representação muito próxima à realidade do caso estudado.

Apesar de a pesquisa ter um caráter quantitativo em seu objetivo principal, a utilização de métodos
qualitativos foram necessários em etapas intermediárias da pesquisa.
Durante a triagem dos dados obtidos, mas especificamente da classificação dos repositórios, foi
necessária a utilização da técnica de entrevistas para viabilizar tal classificação, uma vez que
esta não estava documentada.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Unidade de Análise} \label{Unidade de Análise}

A pesquisa ocorreu em uma empresa brasileira que projeta e desenvolve \textit{hardware} e
\textit{software}.
O enfoque do presente estudo será em um projeto específico de sistema operacional, abarcando todas
as funcionalidades desenvolvidas pela empresa dentro deste sistema operacional.

O sistema conta com 85 funcionalidades de usuário cadastradas e divididas em 316 repositórios
\textit{Git} ativos.
Uma funcionalidade de usuário, no contexto do presente artigo, é uma característica ou função
exercida pelo sistema operacional que seja percebida pelo usuário.
Desta forma, funções internas ao sistema operacional que não geram funcionalidade do ponto de vista
do usuário não são consideradas funcionalidade de usuário.
Cada funcionalidade pode ser implementada por 1 ou mais repositórios e cada repositório pode atender
0 ou mais funcionalidades de usuário. Um exemplo dessa representação pode ser visto na Figura
\ref{fig:features_repos}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=.7\textwidth]{features_repos.png}
    \caption{Exemplo de relação entre repositórios de funcionalidades}
    \label{fig:features_repos}
\end{figure}

No contexto do projeto estudado, os testes de \textit{software} são divididos em duas categorias, de
acordo com o ambiente onde eles são executados.

A primeira categoria são os testes executados em ambientes de máquinas virtuais, ou
\textit{Virtual Machines} (VMs), em servidores especializados.
Essa categoria executa testes funcionais e estruturais de granularidade unitária e de componente,
além de calcular os dados de cobertura de código.
Esses testes são executados em dois momentos:
(1) sempre que um dado código é submetido para revisão, disparado pela submissão do código e
(2) diariamente, disparado por uma tarefa agendada do Jenkins.

A segunda categoria é a de testes executado no equipamento destino.
Nessa etapa existem vários equipamentos que terão seu sistema operacional atualizado com a versão
sobre teste e será executada uma bateria de testes a fim de testar as funcionalidades utilizando
os equipamentos reais e não mais máquinas virtuais.
Essa categoria de testes executa testes funcionais de granularidade de sistema, contendo o sistema
operacional com todos os componentes.

A Figura \ref{fig:pipeline_tests} mostra um resumo das etapas do desenvolvimento de software do
projeto em questão, enfatizando os momentos onde os testes ocorrem.
Analisando a figura, podemos perceber que os testes executados em VMs e disparados pela submissão
para revisão executam com base no código em revisão, já os testes periódicos disparados por tarefa
agendada o Jenkins executam com base no topo do repositório.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{pipeline_tests.png}
    \caption{Pipeline resumido da integração com enfoque na execução dos testes}
    \label{fig:pipeline_tests}
\end{figure}

Outro ponto importante a salientar é o contexto dos dados de cobertura de código.
Os dados gerados são específicos por repositório, ou seja, temos dados de cobertura de código dos
316 repositórios separadamente.

Uma vez que os testes em ambiente de máquinas virtuais são os testes que produzem dados de cobertura
de código, são esses testes que serão utilizados durante o presente estudo, deixando de fora os
testes executados nos equipamentos destino.
Os dados utilizados no estudo compreendem aos dados obtidos do topo dos repositórios, através da
execução periódica disparada pelo Jenkins.

Sobre a linguagem de programação adotada pelo projeto, a esmagadora maioria do código é escrito nas
linguagens C e C++.
A coleta de dados de cobertura de código foi feita em todos os repositórios que reportam cobertura
de códigos C e C++, sendo descartados códigos auxiliares escritos em outras linguagens, como Python
e Shell.

A coleta de dados de falhas reportadas compreende a todas as falhas relacionadas com o projeto
estudado e que não tenham sido corrigidas até o momento da pesquisa.
Isso inclui tanto falhas que ocorreram em campo, quanto falhas identificadas dentro da empresa, seja
por testes em equipamentos destino, testes de aceitação manual ou uso interno.
A decisão considerar apenas as falhas que não foram corrigidas se deu devido ao fato de que ao
considerar o conjunto de todas as falhas, estaríamos tendo interferência do histórico, o que poderia
interferir o resultado do estudo, uma vez que os dados de cobertura de código são relativos ao
momento atual.
E, por fim, a decisão de contabilizar todas as falhas, e não apenas as de campo, se deu devido à
compreensão de que os defeitos encontrados internamente não são menos relevantes, ou menos válidos
para o presente estudo, do que defeitos encontrados em campo.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Coleta de Dados}

O presente estudo se baseia em dados de duas naturezas distintas: (1) dados de falhas reportadas e
(2) dados de cobertura se código.
Ambos os dados foram coletados no dia 28/10/2023, representando o estado atual do projeto, tanto
do ponto de vista das falhas reportadas, quanto do ponto de vista da cobertura de código.
Uma vez que os dados coletados representam o estado o projeto na data de coleta, estes não podem
ser analisados sob uma óptica de evolução temporal do projeto, mas sim sob uma perspectiva de
``fotografia'' do projeto na data de coleta.

Apesar de ambos os dados terem sido coletados na mesma data, tais coletas foram feitas de formas
distintas, as quais serão apresentas nas sessões \ref{sec:falhasReportadas} e \ref{sec:cobertura}.

\subsubsection{Falhas Reportadas} \label{sec:falhasReportadas}

As falhas reportadas compreendem à quantidade de todas as falhas encontradas tanto externamente
(por clientes) quando internamente (por colaboradores).
O projeto estudado utiliza a ferramenta Bugzilla como ferramente gerenciadora de falhas tanto para
falhas descobertas internamente, quanto para falhas descobertas externamente, o que nos permite
acesso à toda a base de dados de falhas do projeto.
Contudo, o mesmo serviço do Bugzilla é utilizado na empresa para reportar falhas de outros projetos
e esse detalhe precisou ser levado em consideração no momento da formulação da busca.

O Bugzilla possui uma ferramenta de busca onde é possível listar bugs de acordo com um determinado
filtro de busca e a saída dessa busca pode ser de dois tipos: (1) HTML, onde é exibida uma interface
web contendo os resultados ou
(2) um arquivo do tipo CSV contendo uma linha para cada resultado encontrado, sendo as colunas
configuráveis via requisição HTML.
O formato escolhido foi o de arquivo CSV pois facilita a automação da triagem de dados.

A busca criada para selecionar a lista de falhas reportadas relacionadas ao projeto e que ainda não
forram solucionadas utilizou filtragem por dois campos do Bugzilla:

\begin{itemize}
    \item \textbf{Status}: Compreende ao estado atual do bug, que pode assumir diversos valores e
          se propõe a informar em qual fase de sua correção ele está, compreendendo desde as fases
          mais iniciais, como \textit{UNCONFIRMED}, que informa que não foi feita uma análise
          inicial, até as fases finais, como \textit{CLOSED}, onde o problema já foi resolvido e
          a solução foi aceita pelas equipes responsáveis pela aceitação.
          O termo escolhido para o filtro desse campo foi o de
          \textbf{``status!=(\textit{RESOLVED} OR \textit{CLOSED})''}.
          Ambos \textit{RESOLVED} e \textit{CLOSED} representam falhas reportadas que já tiveram sua
          correção integrada ao sistema operacional, porém \textit{RESOLVED} é um passo anterior,
          onde os desenvolvedores já fizeram as implementações, testes e integração, porém ainda
          não foi dado o aceite da correção, enquanto \textit{CLOSED} é o estado onde o aceite foi
          concedido.
          Essa escolha foi feita pois no fluxo de trabalho definido na empresa estudada as falhas
          são marcadas como \textit{CLOSED} apenas no fechamento de uma dada versão, sendo que elas
          podem já ter sido corrigidas, logo considerar ambos os termos nos traz uma fidelidade
          maior sobre os dados do projeto;

    \item \textbf{Project}: Compreende ao projeto em que foi encontrado esse problema. Existe um
          campo \textit{Project} específico para o projeto estudado, o qual vai ser utilizado na
          busca. Sendo assim, temos que o termo da busca de projeto é
          \textbf{``project==PROJETO''}, sendo PROJETO o nome que representa o projeto de sistema
          operacional estudado, mas não será divulgado por questões de sigilo empresarial.
\end{itemize}

Unindo os dois termos de busca, um que seleciona o estado da falha e o outro que seleciona o projeto
relativo à falha, temos o seguinte termo de busca:
\textbf{``(status!=(\textit{RESOLVED} OR \textit{CLOSED})) AND (project==PROJETO)''}.
Tal termo de busca tem por objetivo selecionar todas as falhas reportadas que ainda não tem solução
e que foram encontradas no projeto estudado.

Como resultado, o Bugzilla gera arquivo no formato CSV contendo 2 colunas:
(1) campo \textit{bugId}, que se trata de um número identificador do reporte de falha e
(2) campo \textit{component}, que informa em qual funcionalidade de usuário a falha foi encontrada.
O primeiro não terá utilidade no presente estudo, mas é um campo obrigatório nos reportes do
Bugzilla, já o segundo será utilizado para relacionar a quantidade de falhas reportadas com os
índices de cobertura de código.

Com os dados obtidos é possível fazer a contagem de falhas reportadas por funcionalidade de cliente
e tal triagem dos dados será detalhada na sessão \ref{sec:triagem}.
Os dados resultantes da coleta de falhas reportadas não podem ser exibidos na íntegra por questões
de sigilo empresarial, porém foram compilados e anonimizados e serão exibidos na sessão
\ref{sec:resultados}.

\subsubsection{Cobertura de Código} \label{sec:cobertura}

A cobertura de código compreende à uma medida que indica a relação de quantidade de código testado
e código não testado.
O projeto estudado calcula tais dados utilizando a ferramenta gcov e executando os testes escritos
com auxílio do \textit{framework} Google Test, utilizado para desenvolvimento de testes de código
utilizando as linguagens C e C++.

Os dados de cobertura de código estavam inicialmente sendo disponibilizados através do
\textit{plugin} Cobertura \cite{jenkinsCobertura}, disponível do Jenkins
(Figura \ref{fig:pluginCobertura}), e as métricas de cobertura exportadas para o projeto são:
\begin{itemize}
    \item \textbf{Cobertura de Linhas}: Corresponde à quantidade de linhas de código testadas em
          relação ao total de linhas de código válidas do repositório;

    \item \textbf{Cobertura de Arquivos}: Corresponde ao total de arquivos contendo código executado
          nos testes em relação ao total de arquivos C e C++ do repositório;

    \item \textbf{Cobertura de Classes}: Corresponde ao total de classes acessadas nos testes em
          relação ao total de classes C e C++ do repositório;

    \item \textbf{Cobertura de Métodos}: Corresponde ao total de métodos chamados na execução dos
          testes em relação ao total de métodos C e C++ contidos no repositório.
          Um detalhe sobre este campo é que funções em códigos não orientados a objetos também são
          contabilizadas como métodos no contexto nesse reporte.
\end{itemize}

\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{cobertura.jpeg}
    \caption{Exemplo de exibição do \textit{plugin} Cobertura}
    \label{fig:pluginCobertura}
\end{figure}

Dentre todas métricas disponíveis a métrica de Cobertura de Linhas é a mais adequada.
Segundo \cite{coverageMetaAnalysis}, métricas mais genéricas, como cobertura de arquivos ou
cobertura de classes, são menos efetivas para relacionar a qualidade de código, ainda que tenham
validade.
No artigo os autores recomendam a utilização da métrica de Cobertura de Decisão, porém tal métrica
não está disponível atualmente no projeto e não pode ser utilizada.
Em vista disso, a métrica considerada mais adequada foi a de Cobertura de Linhas.

O \textit{plugin} Cobertura exibe dados utilizando uma interface web, o que dificulta a coleta de
dados, uma vez que seria necessário coletar manualmente os dados de cobertura de código dos 316
repositórios.
Para facilitar a coleta, o \textit{script} de geração de dados para o \textit{plugin} Cobertura
foi alterado a fim de gerar dados no formato de arquivos JSON, além do formato original, destinado
ao \textit{plugin} Cobertura.
Como resultado, o \textit{script} passou a gerar um arquivo JSON onde contendo uma lista de
repositórios e seus respectivos dados de cobertura de código, conforme mostra a Figura
\ref{fig:formatoJsonCoverage}.
Tal \textit{script} não pode ser exibido no presente artigo devido a questões relativas a sigilo
empresarial.

\begin{figure}[ht]
\caption{Exemplo de formatação do arquivo JSON gerado após alteração do \textit{script} de
geração de dados de cobertura de código.}
\label{fig:formatoJsonCoverage}
\begin{verbatim}
{
    "Nome do Repositório": {
        "lines-valid": <número de linhas válidas>,
        "line-rate": <taxa de cobertura>,
        "lines-covered": <número de linhas cobertas>
    },
    {
        ...
    }
}
\end{verbatim}
\end{figure}

Dessa forma teremos como resultado um arquivo JSON contendo todos os 316 repositórios e, para cada
um deles, seus respectivos dados de linhas válidas, linhas cobertas e taxa de cobertura.
Os dados de linhas válidas correspondem ao total de linhas de código C e C++, excluindo linhas que
não possuem execução, como linhas em branco, linhas de comentário e linhas de declarações de
métodos, por exemplo. Número de linhas cobertas corresponde ao total de linhas válidas que foram
executadas em pelo menos 1 teste. Por fim, a taxa de cobertura corresponde à divisão das linhas
cobertas pelas linhas válidas, conforme a Figura \ref{fig:formulaTaxaDeCobertura}.

\begin{figure}[ht]
\caption{Fórmula de cálculo de taxa de cobertura.}
\label{fig:formulaTaxaDeCobertura}
    \[ taxaDeCobertura = \frac{linhasValidas}{linhasTotais} \]
\end{figure}

Uma vez que os dados de cobertura de código foram exportados via JSON, eles passaram a estar
disponíveis através do Jenkins.
Dessa forma é foi possível coletar os dados de cobertura por repositório através de
\textit{download} dos arquivos.
Cada repositório exporta seu dados diariamente, conforme descrito na sessão
\ref{Unidade de Análise}, e esses dados foram coletados através de requisições \textbf{wget}
em um terminal Linux com acesso ao Jenkins, sendo feita 1 requisição para cada um dos 316
repositórios.
Ao final, os dados foram organizados, de acordo com o descrito na sessão \ref{sec:triagem}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Análise e Triagem de dados} \label{sec:triagem}
Blablabla

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Limitações Apresentadas}
Blablabla


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Resultados} \label{sec:resultados}
Blablabla

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Falhas Reportadas}
Blablabla

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Cobertura de Código}
Blablabla

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Correlação entre Cobertura de Código e Falhas Reportadas}
Blablabla


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Considerações Finais}
Blablabla
6. Considerações Finais


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{sbc}
\bibliography{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage


\end{document}
